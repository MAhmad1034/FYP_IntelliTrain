{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de6dd8d-d3e5-43d1-8026-96c1196032bd",
   "metadata": {},
   "source": [
    "# ALLAH IS MY LORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a130506-e799-4af8-a4ff-33b712c819c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf6e9d-4d33-4297-ac69-3418033b41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5694e00-1a0e-41e4-ade8-c79426cdf188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "data_dir = \"C:/Users/5A_Traders/Desktop/GTM Data\"\n",
    "image_size = (224, 224)  # MobileNetV2 input size\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497fc58a-8845-4669-940c-7667048a4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1406626d-20dc-49e8-ae67-45d06a989682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1203 images belonging to 3 classes.\n",
      "Found 300 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\",\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    subset=\"validation\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98eae272-ccfb-4ada-90ff-287e33e8bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c350d38d-e34c-4958-80eb-c4e7f0cca720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a73c2a-df06-4aeb-9d04-78a7dbc119d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e82cd42-5055-4361-a2d8-46a4fee4308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c6aa49-7d2d-4198-b9b6-9fb0b2c04e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.5172 - loss: 1.0177 - val_accuracy: 0.9479 - val_loss: 0.2975\n",
      "Epoch 2/10\n",
      "\u001b[1m 1/37\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 737ms/step - accuracy: 0.9688 - loss: 0.2903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.2903 - val_accuracy: 1.0000 - val_loss: 0.3974\n",
      "Epoch 3/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9111 - loss: 0.3172 - val_accuracy: 0.9583 - val_loss: 0.1552\n",
      "Epoch 4/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.1962 - val_accuracy: 1.0000 - val_loss: 0.0567\n",
      "Epoch 5/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9533 - loss: 0.1813 - val_accuracy: 0.9792 - val_loss: 0.0931\n",
      "Epoch 6/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.1950 - val_accuracy: 1.0000 - val_loss: 0.0608\n",
      "Epoch 7/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9666 - loss: 0.1287 - val_accuracy: 0.9896 - val_loss: 0.0727\n",
      "Epoch 8/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9688 - loss: 0.1118 - val_accuracy: 1.0000 - val_loss: 0.0525\n",
      "Epoch 9/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9611 - loss: 0.1198 - val_accuracy: 0.9757 - val_loss: 0.0806\n",
      "Epoch 10/10\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 1.0000 - val_loss: 0.0432\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97cf1f21-25e2-4c7a-adac-98a54a172997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model (unfreeze the base model)\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af7d1d4-42e9-480a-9fc6-faf5dd24a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile again with lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate / 10),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01afa7d8-7bf0-402c-b135-f49a86ea2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.7949 - loss: 0.5442 - val_accuracy: 0.9861 - val_loss: 0.0601\n",
      "Epoch 2/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7895 - loss: 0.2815 - val_accuracy: 1.0000 - val_loss: 0.0645\n",
      "Epoch 3/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - accuracy: 0.9081 - loss: 0.2383 - val_accuracy: 0.9861 - val_loss: 0.0426\n",
      "Epoch 4/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2464 - val_accuracy: 1.0000 - val_loss: 0.0500\n",
      "Epoch 5/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3s/step - accuracy: 0.9538 - loss: 0.1659 - val_accuracy: 0.9931 - val_loss: 0.0405\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4cbb09d-4025-42be-9a32-d85a0ff0aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"mobilenetv2_image_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2056321f-ec01-45c4-a994-45e9a2662575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Function\n",
    "def predict_image(image_path):\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    return train_generator.class_indices, predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda281cd-4a17-40ec-9a97-3fce3479cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Class Indices: {'cats': 0, 'dogs': 1, 'mountain': 2}\n",
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "class_indices, predicted_class = predict_image(\"C:/Users/5A_Traders/Desktop/TestData/pexels-sulimansallehi-1576939.jpg\")\n",
    "print(\"Class Indices:\", class_indices)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0bdbc2-82c2-4bc3-9266-9d1717fe4a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
