{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6438af18-84a4-4518-98d2-0acd0f390631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3101610-329e-42b1-8b15-3922752f4711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load MoveNet model\n",
    "model = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37552c52-2f20-43a8-afd1-c171478fd7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Keypoint extraction functions\n",
    "def process_image(image):\n",
    "    \"\"\"Process image for MoveNet input\"\"\"\n",
    "    image = tf.image.resize_with_pad(image, 192, 192)\n",
    "    return tf.cast(image, dtype=tf.int32)\n",
    "\n",
    "def extract_keypoints(image):\n",
    "    \"\"\"Extract keypoints from image using MoveNet\"\"\"\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    image = process_image(image)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    outputs = movenet(image)\n",
    "    return outputs['output_0'].numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366b8bf3-2ae0-4bab-862e-697efd3fed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prepare training data (assuming images organized in class folders)\n",
    "def prepare_dataset(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Extract keypoints and flatten\n",
    "            keypoints = extract_keypoints(img)\n",
    "            X.append(keypoints.flatten())\n",
    "            y.append(class_idx)\n",
    "    \n",
    "    return np.array(X), np.array(y), class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e0e898-d653-4083-b91b-aceefdeacc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your dataset path\n",
    "X, y, class_names = prepare_dataset('C:/Users/5A_Traders/Downloads/FYP_ON_DEV/FYP_IntelliTrain/PoseEstimation/Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b381406-9993-47b8-89ee-1050d12a62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5206b621-d291-4f2e-9bcc-08b00cc7b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5A_Traders\\miniconda3\\envs\\GTM\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build classifier model\n",
    "classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(51,)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7458e843-ef92-4a45-a3f1-5b2cc6a36873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.7706 - val_accuracy: 0.0000e+00 - val_loss: 0.8411\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.4286 - loss: 0.7548 - val_accuracy: 0.0000e+00 - val_loss: 0.9081\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7143 - loss: 0.6053 - val_accuracy: 0.0000e+00 - val_loss: 0.9547\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7143 - loss: 0.5933 - val_accuracy: 0.0000e+00 - val_loss: 1.0102\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5714 - loss: 0.6866 - val_accuracy: 0.0000e+00 - val_loss: 1.0502\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6429 - loss: 0.6972 - val_accuracy: 0.0000e+00 - val_loss: 1.0719\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "history = classifier.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84d36bb-dbcf-491e-b21e-f85549df4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Live prediction with webcam\n",
    "def live_prediction(class_names):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process frame\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        original_height, original_width = frame.shape[:2]\n",
    "        \n",
    "        # Extract keypoints\n",
    "        keypoints = extract_keypoints(rgb_frame)\n",
    "        features = keypoints.flatten().reshape(1, -1)\n",
    "        \n",
    "        # Predict class\n",
    "        proba = classifier.predict(features, verbose=0)\n",
    "        class_idx = np.argmax(proba)\n",
    "        confidence = np.max(proba)\n",
    "        \n",
    "        # Calculate keypoint transformations\n",
    "        scale = min(192 / original_height, 192 / original_width)\n",
    "        new_height = int(original_height * scale)\n",
    "        new_width = int(original_width * scale)\n",
    "        pad_top = (192 - new_height) // 2\n",
    "        pad_left = (192 - new_width) // 2\n",
    "        \n",
    "        # Draw keypoints\n",
    "        for y_norm, x_norm, conf in keypoints:\n",
    "            if conf > 0.3:\n",
    "                x_pad = x_norm * 192\n",
    "                y_pad = y_norm * 192\n",
    "                x = int((x_pad - pad_left) / scale)\n",
    "                y = int((y_pad - pad_top) / scale)\n",
    "                \n",
    "                # Draw circle if within frame bounds\n",
    "                if 0 <= x < original_width and 0 <= y < original_height:\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        # Display prediction\n",
    "        cv2.putText(frame, f\"{class_names[class_idx]} {confidence:.2f}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Pose Estimation', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start live prediction\n",
    "live_prediction(class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
