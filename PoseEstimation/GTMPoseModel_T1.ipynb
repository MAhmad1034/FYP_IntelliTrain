{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b5b251-17d9-4090-81fa-9197d1ffaaff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5514bbbd-6df7-4d0f-af6f-5a7fc9619b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4337bbf-c85d-4da4-a91d-cac14384f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1474ac-6eb3-439e-9929-0f8a17afebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "image_size = (224, 224)  # Input size for MobileNetV2\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.0001\n",
    "num_keypoints = 17  # Number of keypoints for pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea56cac-e6de-492a-9fa0-c35bd8311b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2 as the backbone\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f5b3be-faf5-40cb-83c2-64abf583dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: Unfreeze the last few layers of the base model\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab3b58d-a477-49f2-b7ee-15f75911c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom regression head for keypoints\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(num_keypoints * 2, activation=\"linear\")(x)  # 2D keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418e2345-4d52-4507-982f-e01de90e96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fafd6cb-00e5-4bd1-96bf-8c4790eceaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "917a34c1-1d9a-43d9-a73c-afae45028e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for pose estimation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14347c9f-fbb8-4728-bbd2-6bcf20a756f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_dir = r'C:/Users/5A_Traders/Downloads/FYP_ON_DEV/FYP_IntelliTrain/Datasets/pose/LSP/images'\n",
    "test_data_dir = r'C:/Users/5A_Traders/Downloads/FYP_ON_DEV/FYP_IntelliTrain/Datasets/pose/LSP/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489c400d-551e-4413-8c1b-cc7b4985cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1936 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for training and validation datasets (to be replaced with pose datasets)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8d9414-c288-43cf-8960-5d07aebdf4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1327ebaf-804d-4db3-a733-e028daec5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for ground truth keypoints (to be aligned with data generators)\n",
    "# Assume `train_keypoints` and `val_keypoints` are numpy arrays of shape (num_samples, num_keypoints*2)\n",
    "train_keypoints = None  # Load or preprocess ground truth keypoints for training\n",
    "val_keypoints = None  # Load or preprocess ground truth keypoints for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d23160-7049-4d9a-8f01-ec1bf5bbdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa069d-ea03-496b-94f6-1b6c5c6f2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pose_estimation_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a04e4-a8cb-433f-a7d6-3567ccec5e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
